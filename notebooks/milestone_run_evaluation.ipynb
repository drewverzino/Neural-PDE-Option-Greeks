{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Neural PDE Option Greeks — Milestone Report Run\n",
    "\n",
    "This notebook reproduces the end-to-end experiment described in the project proposal: generate the full synthetic dataset, train the PINN with boundary and PDE losses, and evaluate price/Greek accuracy plus diagnostic surfaces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "This research notebook mirrors the experimental protocol described in the accompanying report. Each stage is self-contained so results can be reproduced or stress-tested under alternative settings.\n",
    "\n",
    "1. **Environment** – establish paths and execution device.\n",
    "2. **Configuration** – declare dataset and optimisation hyperparameters.\n",
    "3. **Data Preparation** – synthesise Black–Scholes samples for all splits.\n",
    "4. **Model Training** – fit the PINN with adaptive sampling and gradient regularisation.\n",
    "5. **Validation Diagnostics** – benchmark against analytic Greeks in-distribution.\n",
    "6. **Out-of-Sample Benchmark** – evaluate generalisation vs. baseline estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Environment\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / 'src').exists():\n",
    "    for parent in PROJECT_ROOT.parents:\n",
    "        if (parent / 'src').exists():\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError(\"Could not locate project root containing 'src'.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
    "FIGURES_DIR = PROJECT_ROOT / 'figures'\n",
    "RUN_TAG = 'milestone_report_full_run'\n",
    "RUN_RESULTS_DIR = RESULTS_DIR / RUN_TAG\n",
    "FIG_DIR = FIGURES_DIR / RUN_TAG\n",
    "RUN_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "pio.renderers.default = 'notebook'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Experimental Configuration\n",
    "Hyperparameters are grouped into `CONFIG['data']` and `CONFIG['train']` for clarity. The defaults reproduce the settings from our core experiment; edit in-place to explore ablations or stress scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Configuration\n",
    "from pprint import pprint\n",
    "\n",
    "SUCCESS_TARGETS = {\n",
    "    'price_rmse': 1e-2,\n",
    "    'delta_mae': 5e-2,\n",
    "    'gamma_mae': 1e-1,\n",
    "    'theta_mae': 5e-2,\n",
    "    'vega_mae': 5e-2,\n",
    "    'rho_mae': 5e-2,\n",
    "    'gamma_tv_ratio': 2.0,\n",
    "    'ood_price_rmse_ratio': 1.10,\n",
    "    'ood_delta_mae_ratio': 1.10,\n",
    "    'ood_gamma_mae_ratio': 1.10,\n",
    "    'ood_theta_mae_ratio': 1.10,\n",
    "    'ood_vega_mae_ratio': 1.10,\n",
    "    'ood_rho_mae_ratio': 1.10,\n",
    "}\n",
    "\n",
    "FULL_RUN_CONFIG = {\n",
    "    'run_name': RUN_TAG,\n",
    "    'contract': {\n",
    "        'K': 100.0,\n",
    "        'T': 2.0,\n",
    "        'r': 0.05,\n",
    "        't_min': 0.01,\n",
    "        't_max': 1.999,\n",
    "        's_bounds': (20.0, 200.0),\n",
    "        'sigma_bounds': (0.05, 0.6),\n",
    "    },\n",
    "    'data': {\n",
    "        'n_train': 1_000_000,\n",
    "        'n_val':   100_000,\n",
    "        'n_test':  100_000,\n",
    "        'seed':    123,\n",
    "    },\n",
    "    'train': {\n",
    "        'epochs': 100,\n",
    "        'lr': 5e-4,\n",
    "        'warmup_base_lr': 1e-5,\n",
    "        'batch_size': 2048,\n",
    "        'adaptive_sampling': True,\n",
    "        'adaptive_every': 5,\n",
    "        'adaptive_points': 20_000,\n",
    "        'adaptive_radius': 0.1,\n",
    "        'adaptive_eval_samples': 75_000,\n",
    "        'use_warmup': True,\n",
    "        'warmup_steps': 1_000,\n",
    "        'grad_clip': 1.0,\n",
    "        'lambda_reg': 0.01,\n",
    "        'boundary_weight': 1.0,\n",
    "        'boundary_warmup': 25,\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'val_subset': 50_000,\n",
    "        'sample_size': 50_000,\n",
    "        'mc_paths': 100_000,\n",
    "        'surface_grid': 60,\n",
    "        'gamma_tv_grid': 75,\n",
    "        'ood_sigma': (0.60, 0.65),\n",
    "        'ood_samples': 50_000,\n",
    "    },\n",
    "    'success_targets': SUCCESS_TARGETS,\n",
    "}\n",
    "\n",
    "# Quick validation-oriented configuration\n",
    "CONFIG = {\n",
    "    'run_name': RUN_TAG,\n",
    "    'contract': {\n",
    "        'K': 100.0,\n",
    "        'T': 2.0,\n",
    "        'r': 0.05,\n",
    "        't_min': 0.01,\n",
    "        't_max': 1.999,\n",
    "        's_bounds': (20.0, 200.0),\n",
    "        'sigma_bounds': (0.05, 0.6),\n",
    "    },\n",
    "    'data': {\n",
    "        'n_train': 200_000,\n",
    "        'n_val':   40_000,\n",
    "        'n_test':  40_000,\n",
    "        'seed':    123,\n",
    "    },\n",
    "    'train': {\n",
    "        'epochs': 50,\n",
    "        'lr': 5e-4,\n",
    "        'warmup_base_lr': 1e-5,\n",
    "        'batch_size': 4_096,\n",
    "        'adaptive_sampling': True,\n",
    "        'adaptive_every': 5,\n",
    "        'adaptive_points': 10_000,\n",
    "        'adaptive_radius': 0.08,\n",
    "        'adaptive_eval_samples': 50_000,\n",
    "        'use_warmup': True,\n",
    "        'warmup_steps': 500,\n",
    "        'grad_clip': 1.0,\n",
    "        'lambda_reg': 0.01,\n",
    "        'boundary_weight': 0.3,\n",
    "        'boundary_warmup': 25,\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'val_subset': 40_000,\n",
    "        'sample_size': 40_000,\n",
    "        'mc_paths': 50_000,\n",
    "        'surface_grid': 30,\n",
    "        'gamma_tv_grid': 50,\n",
    "        'ood_sigma': (0.60, 0.65),\n",
    "        'ood_samples': 20_000,\n",
    "    },\n",
    "    'success_targets': SUCCESS_TARGETS,\n",
    "}\n",
    "\n",
    "\n",
    "pprint(CONFIG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "We draw $(S,t,\\sigma)$ uniformly over the ranges specified in the configuration and label each sample with the Black–Scholes closed-form price. Time is bounded away from maturity to avoid numerical instability. The generated arrays are persisted to `data/` for auditability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Data generation (train/val/test)\n",
    "from src.data import generate_dataset\n",
    "contract = CONFIG['contract']\n",
    "splits = generate_dataset(\n",
    "    n_train=CONFIG['data']['n_train'],\n",
    "    n_val=CONFIG['data']['n_val'],\n",
    "    n_test=CONFIG['data']['n_test'],\n",
    "    seed=CONFIG['data']['seed'],\n",
    "    output_dir=DATA_DIR,\n",
    "    K=contract['K'],\n",
    "    T=contract['T'],\n",
    "    r=contract['r'],\n",
    "    t_min=contract['t_min'],\n",
    "    t_max=contract['t_max'],\n",
    "    s_bounds=contract['s_bounds'],\n",
    "    sigma_bounds=contract['sigma_bounds'],\n",
    ")\n",
    "list(splits.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "The training routine applies Adam with warmup, gradient clipping, and adaptive sampling concentrated on high-PDE-residual regions. The gradient penalty weight `lambda_reg` moderates surface smoothness, especially for Δ and Γ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Train PINN\n",
    "from src.train import train\n",
    "\n",
    "checkpoint_path = RUN_RESULTS_DIR / 'pinn_checkpoint.pt'\n",
    "plot_path = FIG_DIR / 'loss_curves.html'\n",
    "log_path = RUN_RESULTS_DIR / 'training_history.json'\n",
    "\n",
    "train_cfg = CONFIG['train']\n",
    "model, history = train(\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=(device.type == 'cuda'),\n",
    "    epochs=train_cfg['epochs'],\n",
    "    lr=train_cfg['lr'],\n",
    "    warmup_base_lr=train_cfg['warmup_base_lr'],\n",
    "    batch_size=train_cfg['batch_size'],\n",
    "    data_path=DATA_DIR / 'synthetic_train.npy',\n",
    "    val_path=DATA_DIR / 'synthetic_val.npy',\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    device=device,\n",
    "    adaptive_sampling=train_cfg['adaptive_sampling'],\n",
    "    adaptive_every=train_cfg['adaptive_every'],\n",
    "    adaptive_points=train_cfg['adaptive_points'],\n",
    "    adaptive_radius=train_cfg['adaptive_radius'],\n",
    "    adaptive_eval_samples=train_cfg['adaptive_eval_samples'],\n",
    "    use_warmup=train_cfg['use_warmup'],\n",
    "    warmup_steps=train_cfg['warmup_steps'],\n",
    "    grad_clip=train_cfg['grad_clip'],\n",
    "    lambda_reg=train_cfg['lambda_reg'],\n",
    "    boundary_weight=train_cfg['boundary_weight'],\n",
    "    boundary_warmup=train_cfg['boundary_warmup'],\n",
    "    plot_losses=True,\n",
    "    plot_path=plot_path,\n",
    "    log_path=log_path,\n",
    ")\n",
    "len(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 4.1 Loss Trajectories\n",
    "The Plotly dashboards below provide both linear-scale and log-scale views of the loss components so we can verify balance between the data-fit term and the physics residual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Review saved loss curves\n",
    "from IPython.display import display, HTML\n",
    "loss_html = FIG_DIR / 'loss_curves.html'\n",
    "loss_log_html = FIG_DIR / 'loss_curves_log.html'\n",
    "labels = [\n",
    "    (loss_html, 'Linear scale'),\n",
    "    (loss_log_html, 'Log scale (L_price, L_PDE, L_reg, L_boundary)'),\n",
    "]\n",
    "for html_path, label in labels:\n",
    "    if html_path.exists():\n",
    "        display(HTML(f\"<h4>{label}</h4>\" + html_path.read_text()))\n",
    "    else:\n",
    "        print(f\"{html_path.name} not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 5. Validation Diagnostics & Smoothness Checks\n",
    "We evaluate the trained PINN on a validation subset to compute pricing RMSE and MAE for each Greek\n",
    "against the analytic Black--Scholes references. In parallel we probe smoothness by measuring the\n",
    "total variation of the predicted Gamma surface over a mid-maturity $(S, \\sigma)$ grid, mirroring the\n",
    "smoothness criterion in the milestone report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Validation metrics & smoothness checks\n",
    "from numpy.random import default_rng\n",
    "from src.preprocessing import normalize_inputs, load_normalization_config\n",
    "from src.utils.black_scholes import bs_price, bs_greeks\n",
    "\n",
    "model.eval()\n",
    "rng = default_rng(CONFIG['data']['seed'])\n",
    "norm_config = load_normalization_config(DATA_DIR)\n",
    "val = np.load(DATA_DIR / 'synthetic_val.npy')\n",
    "\n",
    "subset_n = min(CONFIG['evaluation']['val_subset'], len(val))\n",
    "if subset_n < len(val):\n",
    "    idx = rng.choice(len(val), size=subset_n, replace=False)\n",
    "    val_sample = val[idx]\n",
    "else:\n",
    "    val_sample = val\n",
    "\n",
    "S_np, t_np, sigma_np, price_np = val_sample.T\n",
    "contract = CONFIG['contract']\n",
    "\n",
    "def pinn_forward_np(S_values, t_values, sigma_values):\n",
    "    S_tensor = torch.tensor(S_values, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    t_tensor = torch.tensor(t_values, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    sigma_tensor = torch.tensor(sigma_values, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "    features = normalize_inputs(S_tensor, t_tensor, sigma_tensor, config=norm_config)\n",
    "    features = features.detach().clone().requires_grad_(True)\n",
    "    pred = model(features).squeeze()\n",
    "\n",
    "    ones = torch.ones_like(pred)\n",
    "    grad_feats = torch.autograd.grad(\n",
    "        pred,\n",
    "        features,\n",
    "        grad_outputs=ones,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    grad_x_norm = grad_feats[:, 0]\n",
    "    grad_tau_norm = grad_feats[:, 1]\n",
    "    grad_sigma_norm = grad_feats[:, 2]\n",
    "\n",
    "    d2_feats = torch.autograd.grad(\n",
    "        grad_x_norm,\n",
    "        features,\n",
    "        grad_outputs=torch.ones_like(grad_x_norm),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    d2V_dx_norm2 = d2_feats[:, 0]\n",
    "\n",
    "    x_range = max(norm_config.x_max - norm_config.x_min, 1e-6)\n",
    "    tau_range = max(norm_config.tau_range, 1e-6)\n",
    "    sigma_range = max(norm_config.sigma_range, 1e-6)\n",
    "\n",
    "    dx_norm_dx = 2.0 / x_range\n",
    "    dtau_norm_dtau = 2.0 / tau_range\n",
    "    dsigma_norm_dsigma = 2.0 / sigma_range\n",
    "\n",
    "    dV_dx = grad_x_norm * dx_norm_dx\n",
    "    delta = dV_dx / S_tensor\n",
    "\n",
    "    d2V_dx2 = d2V_dx_norm2 * (dx_norm_dx**2)\n",
    "    gamma = d2V_dx2 * (1.0 / (S_tensor**2)) + dV_dx * (-1.0 / (S_tensor**2))\n",
    "\n",
    "    theta = -(grad_tau_norm * dtau_norm_dtau)\n",
    "    vega = grad_sigma_norm * dsigma_norm_dsigma\n",
    "\n",
    "    outputs = dict(\n",
    "        price=pred.detach().cpu().numpy(),\n",
    "        delta=delta.detach().cpu().numpy(),\n",
    "        gamma=gamma.detach().cpu().numpy(),\n",
    "        theta=theta.detach().cpu().numpy(),\n",
    "        vega=vega.detach().cpu().numpy(),\n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "val_outputs = pinn_forward_np(S_np, t_np, sigma_np)\n",
    "analytic = bs_greeks(S_np, norm_config.K, norm_config.T, t_np, sigma_np, norm_config.r)\n",
    "tau_np = np.clip(norm_config.T - t_np, 1e-6, None)\n",
    "rho_pred = tau_np * (S_np * val_outputs['delta'] - val_outputs['price'])\n",
    "\n",
    "val_metrics = {\n",
    "    'price_rmse': float(np.sqrt(np.mean((val_outputs['price'] - price_np) ** 2))),\n",
    "    'delta_mae': float(np.mean(np.abs(val_outputs['delta'] - analytic['delta']))),\n",
    "    'gamma_mae': float(np.mean(np.abs(val_outputs['gamma'] - analytic['gamma']))),\n",
    "    'theta_mae': float(np.mean(np.abs(val_outputs['theta'] - analytic['theta']))),\n",
    "    'vega_mae': float(np.mean(np.abs(val_outputs['vega'] - analytic['vega']))),\n",
    "    'rho_mae': float(np.mean(np.abs(rho_pred - analytic['rho']))),\n",
    "}\n",
    "\n",
    "# Gamma surface total variation on mid-maturity slice\n",
    "grid_n = CONFIG['evaluation']['gamma_tv_grid']\n",
    "S_grid = np.linspace(contract['s_bounds'][0], contract['s_bounds'][1], grid_n)\n",
    "sigma_grid = np.linspace(contract['sigma_bounds'][0], contract['sigma_bounds'][1], grid_n)\n",
    "S_mesh, Sigma_mesh = np.meshgrid(S_grid, sigma_grid, indexing='ij')\n",
    "t_slice = np.full_like(S_mesh, 0.5 * (contract['t_min'] + contract['t_max']))\n",
    "\n",
    "gamma_grid_pred = pinn_forward_np(\n",
    "    S_mesh.reshape(-1),\n",
    "    t_slice.reshape(-1),\n",
    "    Sigma_mesh.reshape(-1),\n",
    ")['gamma'].reshape(S_mesh.shape)\n",
    "gamma_grid_true = bs_greeks(\n",
    "    S_mesh,\n",
    "    norm_config.K,\n",
    "    norm_config.T,\n",
    "    t_slice,\n",
    "    Sigma_mesh,\n",
    "    norm_config.r,\n",
    ")['gamma']\n",
    "\n",
    "def total_variation(surface: np.ndarray) -> float:\n",
    "    return float(np.abs(np.diff(surface, axis=0)).sum() + np.abs(np.diff(surface, axis=1)).sum())\n",
    "\n",
    "val_metrics['gamma_tv_pred'] = total_variation(gamma_grid_pred)\n",
    "val_metrics['gamma_tv_true'] = total_variation(gamma_grid_true)\n",
    "val_metrics['gamma_tv_ratio'] = val_metrics['gamma_tv_pred'] / max(val_metrics['gamma_tv_true'], 1e-12)\n",
    "\n",
    "val_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 6. Volatility Stress Test $ (\\sigma \\in [0.60, 0.65]) $\n",
    "To quantify out-of-distribution robustness we evaluate the model on options drawn from a higher\n",
    "volatility band than the training data. Metrics are reported alongside their degradation relative to\n",
    "the validation split, matching the OOD criterion in the milestone report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Volatility stress metrics\n",
    "sigma_low, sigma_high = CONFIG['evaluation']['ood_sigma']\n",
    "ood_samples = CONFIG['evaluation']['ood_samples']\n",
    "ood_rng = default_rng(CONFIG['data']['seed'] + 7)\n",
    "\n",
    "S_ood = ood_rng.uniform(contract['s_bounds'][0], contract['s_bounds'][1], size=ood_samples)\n",
    "t_ood = ood_rng.uniform(contract['t_min'], contract['t_max'], size=ood_samples)\n",
    "sigma_ood = ood_rng.uniform(sigma_low, sigma_high, size=ood_samples)\n",
    "\n",
    "price_ood = bs_price(S_ood, norm_config.K, norm_config.T, t_ood, sigma_ood, norm_config.r)\n",
    "ood_outputs = pinn_forward_np(S_ood, t_ood, sigma_ood)\n",
    "analytic_ood = bs_greeks(S_ood, norm_config.K, norm_config.T, t_ood, sigma_ood, norm_config.r)\n",
    "tau_ood = np.clip(norm_config.T - t_ood, 1e-6, None)\n",
    "rho_ood_pred = tau_ood * (S_ood * ood_outputs['delta'] - ood_outputs['price'])\n",
    "\n",
    "ood_metrics = {\n",
    "    'price_rmse': float(np.sqrt(np.mean((ood_outputs['price'] - price_ood) ** 2))),\n",
    "    'delta_mae': float(np.mean(np.abs(ood_outputs['delta'] - analytic_ood['delta']))),\n",
    "    'gamma_mae': float(np.mean(np.abs(ood_outputs['gamma'] - analytic_ood['gamma']))),\n",
    "    'theta_mae': float(np.mean(np.abs(ood_outputs['theta'] - analytic_ood['theta']))),\n",
    "    'vega_mae': float(np.mean(np.abs(ood_outputs['vega'] - analytic_ood['vega']))),\n",
    "    'rho_mae': float(np.mean(np.abs(rho_ood_pred - analytic_ood['rho']))),\n",
    "}\n",
    "\n",
    "ood_ratios = {\n",
    "    key: ood_metrics[key] / val_metrics[key] if val_metrics.get(key) else np.nan\n",
    "    for key in ('price_rmse', 'delta_mae', 'gamma_mae', 'theta_mae', 'vega_mae', 'rho_mae')\n",
    "}\n",
    "\n",
    "ood_metrics['ratios_vs_val'] = ood_ratios\n",
    "ood_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 7. Out-of-Sample Benchmark\n",
    "We invoke the evaluation utility to benchmark the PINN against finite-difference and Monte Carlo baselines on held-out data. The function logs metrics and exports interactive plots (2D overlays, error histograms, and 3D surfaces for price, Δ, Γ, Θ, ν, and ρ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Out-of-sample evaluation & visuals\n",
    "from src.test import evaluate_oos\n",
    "import json\n",
    "\n",
    "oos_metrics = evaluate_oos(\n",
    "    data_path=DATA_DIR / 'synthetic_test.npy',\n",
    "    model_path=checkpoint_path,\n",
    "    device=device,\n",
    "    sample_size=CONFIG['evaluation']['sample_size'],\n",
    "    mc_paths=CONFIG['evaluation']['mc_paths'],\n",
    "    seed=CONFIG['data']['seed'],\n",
    "    fig_dir=FIG_DIR / 'oos',\n",
    "    surface_grid=CONFIG['evaluation']['surface_grid'],\n",
    ")\n",
    "with open(RUN_RESULTS_DIR / 'oos_metrics.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(oos_metrics, fp, indent=2)\n",
    "oos_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 8. Scorecard vs. Milestone Targets\n",
    "The table below compares measured metrics against the success thresholds defined in the milestone\n",
    "report. Out-of-distribution entries capture the degradation ratios relative to the validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Scorecard computation\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "success_targets = CONFIG.get('success_targets', {})\n",
    "score_rows = []\n",
    "\n",
    "def _format_label(metric_key: str) -> str:\n",
    "    return metric_key.replace('_', ' ').title()\n",
    "\n",
    "for metric, target in success_targets.items():\n",
    "    if metric.startswith('ood_') and metric.endswith('_ratio'):\n",
    "        base_key = metric[len('ood_'):-len('_ratio')]\n",
    "        value = ood_metrics['ratios_vs_val'].get(base_key)\n",
    "    elif metric == 'gamma_tv_ratio':\n",
    "        value = val_metrics.get('gamma_tv_ratio')\n",
    "    else:\n",
    "        value = val_metrics.get(metric)\n",
    "\n",
    "    if value is None or np.isnan(value):\n",
    "        status = '⚪️'\n",
    "        display_value = 'n/a'\n",
    "    else:\n",
    "        status = '✅' if value <= target else '⚠️'\n",
    "        display_value = f\"{value:.4g}\"\n",
    "\n",
    "    score_rows.append((_format_label(metric), display_value, f\"{target:.4g}\", status))\n",
    "\n",
    "lines = [\"| Metric | Value | Target | Status |\", \"|---|---|---|---|\"]\n",
    "for label, value, target, status in score_rows:\n",
    "    lines.append(f\"| {label} | {value} | {target} | {status} |\")\n",
    "\n",
    "display(Markdown(\"\\n\".join(lines)))\n",
    "\n",
    "summary = {\n",
    "    'validation': val_metrics,\n",
    "    'ood': ood_metrics,\n",
    "    'oos': oos_metrics,\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Supplementary Artifacts\n",
    "from IPython.display import display, Markdown, JSON, IFrame\n",
    "import json\n",
    "\n",
    "def _embed_html(title: str, path, height: int = 520):\n",
    "    display(Markdown(f\"**{title}**\"))\n",
    "    if path.exists():\n",
    "        rel_path = path.relative_to(PROJECT_ROOT)\n",
    "        display(IFrame(src=rel_path.as_posix(), width='100%', height=height))\n",
    "    else:\n",
    "        display(Markdown(f\"_Missing: {path}_\"))\n",
    "\n",
    "# Training history snapshot\n",
    "history_path = RUN_RESULTS_DIR / 'training_history.json'\n",
    "display(Markdown('**Training History (last 3 epochs)**'))\n",
    "if history_path.exists():\n",
    "    with open(history_path) as fp:\n",
    "        hist = json.load(fp)\n",
    "    display(JSON(hist[-3:]))\n",
    "else:\n",
    "    display(Markdown('_No training history found._'))\n",
    "\n",
    "# Loss curves\n",
    "_embed_html('Loss Curves (linear scale)', FIG_DIR / 'loss_curves.html')\n",
    "_embed_html('Loss Curves (log scale)', FIG_DIR / 'loss_curves_log.html')\n",
    "\n",
    "# Out-of-sample dashboards\n",
    "oos_dir = FIG_DIR / 'oos'\n",
    "display(Markdown('**Out-of-Sample Dashboards**'))\n",
    "if oos_dir.exists():\n",
    "    html_files = sorted(oos_dir.glob('*.html'))\n",
    "    if html_files:\n",
    "        for html_path in html_files:\n",
    "            title = html_path.stem.replace('_', ' ').title()\n",
    "            _embed_html(title, html_path, height=420)\n",
    "    else:\n",
    "        display(Markdown('_No OOS HTML files found._'))\n",
    "else:\n",
    "    display(Markdown('_No OOS figures directory found._'))\n",
    "\n",
    "# OOS metrics JSON\n",
    "oos_metrics_path = RUN_RESULTS_DIR / 'oos_metrics.json'\n",
    "display(Markdown('**Latest OOS Metrics**'))\n",
    "if oos_metrics_path.exists():\n",
    "    with open(oos_metrics_path) as fp:\n",
    "        display(JSON(json.load(fp)))\n",
    "else:\n",
    "    display(Markdown('_OOS metrics JSON not found._'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 9. Findings\n",
    "- Validation targets focus on price RMSE and Greek MAE; the accompanying scorecard cell reports the\n",
    "  latest measurements alongside the milestone thresholds.\n",
    "- Gamma smoothness is quantified via the total-variation ratio on a mid-maturity surface to ensure\n",
    "  hedgeable curvature. Ratios above the target flag scenarios where the Sobolev penalty requires\n",
    "  retuning.\n",
    "- The volatility stress test provides the degradation ratios for $\\sigma \\in [0.60, 0.65]$, making it\n",
    "  easy to verify the OOD criterion (\n",
    "  $<10\\%$ degradation) without re-running plots.\n",
    "- Out-of-sample benchmarks remain available via `evaluate_oos`, including finite-difference and Monte\n",
    "  Carlo baselines, so downstream reports can reference the same JSON/HTML artifacts listed above.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
