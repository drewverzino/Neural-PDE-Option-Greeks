{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìó Sanity Check Notebook ‚Äî PINN Greeks Project\n",
    "\n",
    "Use this notebook to **verify your environment, data, baselines, and a tiny PINN training loop** end-to-end.\n",
    "\n",
    "**What this does:**\n",
    "1. Prints package versions and creates required folders\n",
    "2. Imports Black‚ÄìScholes utilities (or defines fallbacks)\n",
    "3. Generates a *small* synthetic dataset for quick checks\n",
    "4. Plots price & Greek curves\n",
    "5. Runs finite-difference and Monte Carlo baselines vs analytic\n",
    "6. Trains a **tiny** PINN for a few epochs to confirm gradients & loss\n",
    "7. Plots predicted surface and a rough PDE residual heatmap\n",
    "\n",
    "> ‚ö†Ô∏è This is **not** for full experiments ‚Äî keep it quick so you can iterate fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12324c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/amv10802/Documents/Neural-PDE-Option-Greeks\n",
      "{'python': '3.11.7', 'numpy': '2.3.3', 'matplotlib': '3.10.7', 'torch': '2.8.0'}\n"
     ]
    }
   ],
   "source": [
    "# 0) Environment & folders\n",
    "import os, sys, math, json, random, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_OK = True\n",
    "except Exception as e:\n",
    "    TORCH_OK = False\n",
    "    print(\"PyTorch import failed:\", e)\n",
    "\n",
    "NOTEBOOK_CWD = Path.cwd().resolve()\n",
    "CANDIDATES = [NOTEBOOK_CWD, NOTEBOOK_CWD.parent, NOTEBOOK_CWD.parent.parent]\n",
    "BASE = None\n",
    "for candidate in CANDIDATES:\n",
    "    if (candidate / \"src\").is_dir():\n",
    "        BASE = candidate\n",
    "        break\n",
    "\n",
    "if BASE is None:\n",
    "    raise RuntimeError(f\"Could not locate project root from {NOTEBOOK_CWD}\")\n",
    "\n",
    "print(f\"Project root: {BASE}\")\n",
    "if str(BASE) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE))\n",
    "\n",
    "for d in [\n",
    "    'src', 'src/utils', 'src/models', 'src/baselines',\n",
    "    'data', 'results', 'figures', 'figures/data_exploration',\n",
    "    'figures/training_curves', 'figures/residual_heatmaps', 'figures/final_results']:\n",
    "    (BASE / d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_DIR = BASE / 'data'\n",
    "FIGURES_DIR = BASE / 'figures'\n",
    "RESULTS_DIR = BASE / 'results'\n",
    "\n",
    "print({\n",
    "    'python': sys.version.split()[0],\n",
    "    'numpy': np.__version__,\n",
    "    'matplotlib': matplotlib.__version__,\n",
    "    'torch': torch.__version__ if TORCH_OK else None,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6516295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported bs_price/bs_greeks from src.utils.black_scholes\n"
     ]
    }
   ],
   "source": [
    "# 1) Black‚ÄìScholes utilities ‚Äî import if available, otherwise define minimal fallbacks\n",
    "from math import log, sqrt, exp\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def _bs_price(S, K, T, t, sigma, r=0.05, option_type=\"call\"):\n",
    "    tau = max(T - t, 1e-6)\n",
    "    d1 = (log(S/K) + (r + 0.5*sigma**2)*tau) / (sigma*sqrt(tau))\n",
    "    d2 = d1 - sigma*sqrt(tau)\n",
    "    if option_type == 'call':\n",
    "        return S*norm.cdf(d1) - K*exp(-r*tau)*norm.cdf(d2)\n",
    "    return K*exp(-r*tau)*norm.cdf(-d2) - S*norm.cdf(-d1)\n",
    "\n",
    "\n",
    "def _bs_greeks(S, K, T, t, sigma, r=0.05):\n",
    "    tau = max(T - t, 1e-6)\n",
    "    d1 = (log(S/K) + (r + 0.5*sigma**2)*tau) / (sigma*sqrt(tau))\n",
    "    d2 = d1 - sigma*sqrt(tau)\n",
    "    delta = norm.cdf(d1)\n",
    "    gamma = norm.pdf(d1)/(S*sigma*sqrt(tau))\n",
    "    theta = -(S*norm.pdf(d1)*sigma)/(2*sqrt(tau)) - r*K*exp(-r*tau)*norm.cdf(d2)\n",
    "    vega = S*norm.pdf(d1)*sqrt(tau)\n",
    "    rho = K*tau*exp(-r*tau)*norm.cdf(d2)\n",
    "    return dict(delta=delta, gamma=gamma, theta=theta, vega=vega, rho=rho)\n",
    "\n",
    "\n",
    "try:\n",
    "    from src.utils.black_scholes import bs_price, bs_greeks\n",
    "    print(\"Imported bs_price/bs_greeks from src.utils.black_scholes\")\n",
    "except Exception:\n",
    "    bs_price, bs_greeks = _bs_price, _bs_greeks\n",
    "    print(\"Using fallback Black‚ÄìScholes implementations (define src/utils/black_scholes.py to override)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bc169c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Generate a tiny synthetic dataset (quick sanity only)\n",
    "rng = np.random.default_rng(7)\n",
    "K, T, r = 100.0, 2.0, 0.05\n",
    "N_SMALL = 5_000\n",
    "S = rng.uniform(20, 200, N_SMALL)\n",
    "t = rng.uniform(0.01, 2.0, N_SMALL)\n",
    "sigma = rng.uniform(0.05, 0.6, N_SMALL)\n",
    "V = np.array([bs_price(S[i], K, T, t[i], sigma[i], r) for i in range(N_SMALL)], dtype=float)\n",
    "small = np.stack([S, t, sigma, V], axis=1)\n",
    "np.save(DATA_DIR / 'sanity_small.npy', small)\n",
    "small.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2a3d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figures/data_exploration/*\n"
     ]
    }
   ],
   "source": [
    "# 3) Plot price and a couple of Greeks vs S (fixed t, sigma)\n",
    "matplotlib.use('Agg')\n",
    "S_line = np.linspace(20, 200, 400)\n",
    "t0, sig0 = 1.0, 0.2\n",
    "V_line = [bs_price(s, K, T, t0, sig0, r) for s in S_line]\n",
    "G_line = [bs_greeks(s, K, T, t0, sig0, r) for s in S_line]\n",
    "Delta = [g['delta'] for g in G_line]\n",
    "Gamma = [g['gamma'] for g in G_line]\n",
    "\n",
    "plt.figure(); plt.plot(S_line, V_line); plt.xlabel('S'); plt.ylabel('Price'); plt.title('BS Price vs S')\n",
    "plt.tight_layout(); plt.savefig(FIGURES_DIR / 'data_exploration' / 'price_vs_S.png')\n",
    "\n",
    "plt.figure(); plt.plot(S_line, Delta); plt.xlabel('S'); plt.ylabel('Delta'); plt.title('Delta vs S')\n",
    "plt.tight_layout(); plt.savefig(FIGURES_DIR / 'data_exploration' / 'delta_vs_S.png')\n",
    "\n",
    "plt.figure(); plt.plot(S_line, Gamma); plt.xlabel('S'); plt.ylabel('Gamma'); plt.title('Gamma vs S')\n",
    "plt.tight_layout(); plt.savefig(FIGURES_DIR / 'data_exploration' / 'gamma_vs_S.png')\n",
    "\n",
    "print('Saved: figures/data_exploration/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b642bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analytic_delta': np.float64(0.6368306511756191), 'fd_delta': np.float64(0.6368306425763137), 'mc_delta': np.float64(0.6352971442332153), 'fd_gamma': np.float64(0.018762017077733617), 'analytic_gamma': np.float64(0.018762017345846895)}\n"
     ]
    }
   ],
   "source": [
    "# 4) Baselines: finite-difference & Monte Carlo vs analytic (single point + sweep)\n",
    "def fd_delta_gamma(S0, eps=1e-2):\n",
    "    V0 = bs_price(S0, K, T, 1.0, 0.2, r)\n",
    "    Vp = bs_price(S0+eps, K, T, 1.0, 0.2, r)\n",
    "    Vm = bs_price(S0-eps, K, T, 1.0, 0.2, r)\n",
    "    delta = (Vp - Vm)/(2*eps)\n",
    "    gamma = (Vp - 2*V0 + Vm)/(eps**2)\n",
    "    return delta, gamma\n",
    "\n",
    "def mc_pathwise_delta(S0, K=100, T=1.0, r=0.05, sigma=0.2, N=20_000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Z = rng.standard_normal(N)\n",
    "    ST = S0*np.exp((r - 0.5*sigma**2)*T + sigma*np.sqrt(T)*Z)\n",
    "    payoff = np.maximum(ST - K, 0)\n",
    "    dS = ST / S0\n",
    "    return np.exp(-r*T) * np.mean(dS * (ST > K))\n",
    "\n",
    "S0 = 100\n",
    "true = bs_greeks(S0, K, T, 1.0, 0.2, r)\n",
    "fd_d, fd_g = fd_delta_gamma(S0)\n",
    "mc_d = mc_pathwise_delta(S0)\n",
    "print({\n",
    "    'analytic_delta': true['delta'],\n",
    "    'fd_delta': fd_d,\n",
    "    'mc_delta': mc_d,\n",
    "    'fd_gamma': fd_g,\n",
    "    'analytic_gamma': true['gamma'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0513791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5  loss=2359.298193\n",
      "epoch 2/5  loss=598.572986\n",
      "epoch 3/5  loss=454.865417\n",
      "epoch 4/5  loss=504.290186\n",
      "epoch 5/5  loss=364.013098\n",
      "Saved: figures/training_curves/tiny_pinn_loss.png\n"
     ]
    }
   ],
   "source": [
    "# 5) Tiny PINN ‚Äî quick training to confirm gradients & loss decrease\n",
    "if not TORCH_OK:\n",
    "    print('PyTorch not available ‚Äî skipping PINN training cell.')\n",
    "else:\n",
    "    import torch, torch.nn as nn, torch.nn.functional as F\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    class ResidualBlock(nn.Module):\n",
    "        def __init__(self, d=64):\n",
    "            super().__init__()\n",
    "            self.fc1, self.fc2 = nn.Linear(d,d), nn.Linear(d,d)\n",
    "        def forward(self, x):\n",
    "            h = F.relu(self.fc1(x))\n",
    "            h = self.fc2(h)\n",
    "            return F.relu(h + x)\n",
    "\n",
    "    class TinyPINN(nn.Module):\n",
    "        def __init__(self, d=64, L=3):\n",
    "            super().__init__()\n",
    "            self.inp = nn.Linear(3, d)\n",
    "            self.blocks = nn.ModuleList([ResidualBlock(d) for _ in range(L)])\n",
    "            self.out = nn.Linear(d, 1)\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.inp(x))\n",
    "            for b in self.blocks:\n",
    "                x = b(x)\n",
    "            return self.out(x)\n",
    "\n",
    "    arr = np.load(DATA_DIR / 'sanity_small.npy')\n",
    "    S_t, t_t, s_t, V_t = [torch.tensor(arr[:,i], dtype=torch.float32) for i in range(4)]\n",
    "    ds = TensorDataset(S_t, t_t, s_t, V_t)\n",
    "    dl = DataLoader(ds, batch_size=1024, shuffle=True)\n",
    "\n",
    "    def pde_residual(model, S, t, sigma, r=0.05):\n",
    "        S = S.clone().requires_grad_(True)\n",
    "        t = t.clone().requires_grad_(True)\n",
    "        x = torch.stack([S, t, sigma], dim=1)\n",
    "        V = model(x)\n",
    "        ones = torch.ones_like(V)\n",
    "        dVdS = torch.autograd.grad(V, S, grad_outputs=ones, create_graph=True)[0]\n",
    "        d2VdS2 = torch.autograd.grad(dVdS, S, grad_outputs=torch.ones_like(dVdS), create_graph=True)[0]\n",
    "        dVdt = torch.autograd.grad(V, t, grad_outputs=ones, create_graph=True)[0]\n",
    "        return dVdt + 0.5*sigma**2*S**2*d2VdS2 + r*S*dVdS - r*V\n",
    "\n",
    "    model = TinyPINN(d=64, L=3)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    losses = []\n",
    "    EPOCHS = 5  # keep small for sanity\n",
    "    for ep in range(EPOCHS):\n",
    "        tot = 0.0\n",
    "        for S_b, t_b, s_b, V_b in dl:\n",
    "            opt.zero_grad()\n",
    "            preds = model(torch.stack([S_b, t_b, s_b], dim=1))\n",
    "            L_price = ((preds.squeeze() - V_b)**2).mean()\n",
    "            L_pde = (pde_residual(model, S_b, t_b, s_b)**2).mean()\n",
    "            loss = L_price + L_pde\n",
    "            loss.backward(); opt.step()\n",
    "            tot += float(loss.detach().cpu())\n",
    "        losses.append(tot/len(dl))\n",
    "        print(f\"epoch {ep+1}/{EPOCHS}  loss={losses[-1]:.6f}\")\n",
    "\n",
    "    # plot loss\n",
    "    plt.figure(); plt.plot(losses)\n",
    "    plt.xlabel('epoch'); plt.ylabel('loss'); plt.title('Tiny PINN loss (sanity)')\n",
    "    plt.tight_layout(); plt.savefig(FIGURES_DIR / 'training_curves' / 'tiny_pinn_loss.png')\n",
    "    print('Saved: figures/training_curves/tiny_pinn_loss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704536ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figures/final_results/surface_coarse.png, figures/residual_heatmaps/pde_residual_coarse.png\n"
     ]
    }
   ],
   "source": [
    "# 6) Surface & PDE residual heatmap (coarse)\n",
    "if not TORCH_OK:\n",
    "    print('PyTorch not available ‚Äî skipping surface & residual plots.')\n",
    "else:\n",
    "    Sg = torch.linspace(20, 200, 50)\n",
    "    sg = torch.linspace(0.05, 0.6, 50)\n",
    "    Smesh, Sigmesh = torch.meshgrid(Sg, sg, indexing='ij')\n",
    "    tgrid = torch.full_like(Smesh, 1.0)\n",
    "\n",
    "    def pde_residual_grid(model, S, t, sigma, r=0.05):\n",
    "        S = S.clone().requires_grad_(True)\n",
    "        t = t.clone().requires_grad_(True)\n",
    "        x = torch.stack([S.flatten(), t.flatten(), sigma.flatten()], dim=1)\n",
    "        V = model(x).reshape_as(S)\n",
    "        ones = torch.ones_like(V)\n",
    "        dVdS = torch.autograd.grad(V, S, grad_outputs=ones, create_graph=True)[0]\n",
    "        d2VdS2 = torch.autograd.grad(dVdS, S, grad_outputs=torch.ones_like(dVdS), create_graph=True)[0]\n",
    "        dVdt = torch.autograd.grad(V, t, grad_outputs=ones, create_graph=True)[0]\n",
    "        return (dVdt + 0.5*sigma**2*S**2*d2VdS2 + 0.05*S*dVdS - 0.05*V).detach()\n",
    "\n",
    "    # Reuse TinyPINN from prior cell if present\n",
    "    try:\n",
    "        model\n",
    "    except NameError:\n",
    "        from math import isfinite\n",
    "        print('TinyPINN not found in memory; re-instantiating untrained model for plotting.')\n",
    "        import torch.nn as nn, torch.nn.functional as F\n",
    "        class ResidualBlock(nn.Module):\n",
    "            def __init__(self, d=64):\n",
    "                super().__init__(); self.fc1, self.fc2 = nn.Linear(d,d), nn.Linear(d,d)\n",
    "            def forward(self, x):\n",
    "                h = F.relu(self.fc1(x)); h = self.fc2(h); return F.relu(h+x)\n",
    "        class TinyPINN(nn.Module):\n",
    "            def __init__(self, d=64, L=3):\n",
    "                super().__init__(); self.inp = nn.Linear(3,d); self.blocks = nn.ModuleList([ResidualBlock(d) for _ in range(L)]); self.out = nn.Linear(d,1)\n",
    "            def forward(self, x):\n",
    "                x = F.relu(self.inp(x))\n",
    "                for b in self.blocks: x = b(x)\n",
    "                return self.out(x)\n",
    "        model = TinyPINN()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Vpred = model(torch.stack([Smesh.flatten(), tgrid.flatten(), Sigmesh.flatten()], dim=1)).reshape_as(Smesh)\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    cp = plt.contourf(Sg.numpy(), sg.numpy(), Vpred.numpy().T, levels=30)\n",
    "    plt.xlabel('S'); plt.ylabel('œÉ'); plt.title('Predicted Price Surface (coarse)')\n",
    "    plt.colorbar(cp); plt.tight_layout(); plt.savefig(FIGURES_DIR / 'final_results' / 'surface_coarse.png')\n",
    "\n",
    "    R = pde_residual_grid(model, Smesh, tgrid, Sigmesh)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    cp = plt.contourf(Sg.numpy(), sg.numpy(), R.numpy().T, levels=30)\n",
    "    plt.xlabel('S'); plt.ylabel('œÉ'); plt.title('PDE Residual (coarse, sanity)')\n",
    "    plt.colorbar(cp); plt.tight_layout(); plt.savefig(FIGURES_DIR / 'residual_heatmaps' / 'pde_residual_coarse.png')\n",
    "    print('Saved: figures/final_results/surface_coarse.png, figures/residual_heatmaps/pde_residual_coarse.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ What ‚Äúgood‚Äù looks like (for sanity)\n",
    "\n",
    "- The three files in `figures/data_exploration/` exist and look reasonable (monotonic Delta, peaked Gamma).\n",
    "- Baselines: FD Œî and MC Œî are in the same *ballpark* as analytic Œî at S‚âàK; FD Œì roughly matches analytic Œì.\n",
    "- Tiny PINN: the loss plot decreases over a few epochs (it doesn‚Äôt need to be perfect here).\n",
    "- Surface & PDE residual plots are produced (patterns may be rough without full training).\n",
    "\n",
    "If any of these don‚Äôt happen, focus on that section first before moving to full experiments."
   ]
  }
 ],
 "metadata": {
  "created": "2025-10-13T19:59:10.358348Z",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
