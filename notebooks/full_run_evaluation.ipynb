{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Neural PDE Option Greeks — Full Proposal Run\n",
    "\n",
    "This notebook reproduces the end-to-end experiment described in the project proposal: generate the full synthetic dataset, train the PINN with boundary and PDE losses, and evaluate price/Greek accuracy plus diagnostic surfaces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "This research notebook mirrors the experimental protocol described in the accompanying report. Each stage is self-contained so results can be reproduced or stress-tested under alternative settings.\n",
    "\n",
    "1. **Environment** – establish paths and execution device.\n",
    "2. **Configuration** – declare dataset and optimisation hyperparameters.\n",
    "3. **Data Preparation** – synthesise Black–Scholes samples for all splits.\n",
    "4. **Model Training** – fit the PINN with adaptive sampling and gradient regularisation.\n",
    "5. **Validation Diagnostics** – benchmark against analytic Greeks in-distribution.\n",
    "6. **Out-of-Sample Benchmark** – evaluate generalisation vs. baseline estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Environment\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / 'src').exists():\n",
    "    for parent in PROJECT_ROOT.parents:\n",
    "        if (parent / 'src').exists():\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError(\"Could not locate project root containing 'src'.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
    "FIGURES_DIR = PROJECT_ROOT / 'figures'\n",
    "RUN_TAG = 'proposal_full_run'\n",
    "RUN_RESULTS_DIR = RESULTS_DIR / RUN_TAG\n",
    "FIG_DIR = FIGURES_DIR / RUN_TAG\n",
    "RUN_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "pio.renderers.default = 'notebook'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Experimental Configuration\n",
    "Hyperparameters are grouped into `CONFIG['data']` and `CONFIG['train']` for clarity. The defaults reproduce the settings from our core experiment; edit in-place to explore ablations or stress scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Configuration\n",
    "# CONFIG = {\n",
    "#     'run_name': RUN_TAG,\n",
    "#     'contract': {\n",
    "#         'K': 100.0,\n",
    "#         'T': 2.0,\n",
    "#         'r': 0.05,\n",
    "#         't_min': 0.01,\n",
    "#         't_max': 1.999,\n",
    "#         's_bounds': (20.0, 200.0),\n",
    "#         'sigma_bounds': (0.05, 0.6),\n",
    "#     },\n",
    "#     'data': {\n",
    "#         'n_train': 1_000_000,\n",
    "#         'n_val':   100_000,\n",
    "#         'n_test':  100_000,\n",
    "#         'seed':    123,\n",
    "#     },\n",
    "#     'train': {\n",
    "#         'epochs': 100,\n",
    "#         'lr': 1e-3,\n",
    "#         'batch_size': 2048,\n",
    "#         'adaptive_sampling': True,\n",
    "#         'adaptive_every': 50,\n",
    "#         'adaptive_points': 10_000,\n",
    "#         'adaptive_radius': 0.1,\n",
    "#         'adaptive_eval_samples': 50_000,\n",
    "#         'use_warmup': True,\n",
    "#         'warmup_steps': 1_000,\n",
    "#         'grad_clip': 1.0,\n",
    "#         'lambda_reg': 0.01,\n",
    "#         'boundary_weight': 1.0,\n",
    "#         'boundary_warmup': 10,\n",
    "#     },\n",
    "#     'evaluation': {\n",
    "#         'val_subset': 50_000,\n",
    "#         'sample_size': 50_000,\n",
    "#         'mc_paths': 100_000,\n",
    "#         'surface_grid': 60,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# 1) Configuration - Quick 20 Epoch Run\n",
    "CONFIG = {\n",
    "    'run_name': RUN_TAG,\n",
    "    'contract': {\n",
    "        'K': 100.0,\n",
    "        'T': 2.0,\n",
    "        'r': 0.05,\n",
    "        't_min': 0.01,\n",
    "        't_max': 1.999,\n",
    "        's_bounds': (20.0, 200.0),\n",
    "        'sigma_bounds': (0.05, 0.6),\n",
    "    },\n",
    "    'data': {\n",
    "        'n_train': 1_000_000,\n",
    "        'n_val':   100_000,\n",
    "        'n_test':  100_000,\n",
    "        'seed':    123,\n",
    "    },\n",
    "    'train': {\n",
    "        'epochs': 20,                    # Short run for validation\n",
    "        'lr': 1e-3,                      # Standard rate\n",
    "        'batch_size': 1024,              # Good gradient estimates\n",
    "        'adaptive_sampling': True,       # Enable\n",
    "        'adaptive_every': 10,            # Only at epoch 10 and 20\n",
    "        'adaptive_points': 8_000,        # Slightly fewer points\n",
    "        'adaptive_radius': 0.08,         # Focused sampling\n",
    "        'adaptive_eval_samples': 30_000,  # Faster eval\n",
    "        'use_warmup': True,              # Keep warmup\n",
    "        'warmup_steps': 300,             # ~0.3 epochs\n",
    "        'grad_clip': 1.0,                # Standard clipping\n",
    "        'lambda_reg': 0.005,             # Balanced smoothing\n",
    "        'boundary_weight': 1.0,          # Full weight\n",
    "        'boundary_warmup': 5,            # Ramp up faster (over 5 epochs)\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'val_subset': 20_000,            # Faster validation\n",
    "        'sample_size': 20_000,           # Faster OOS eval\n",
    "        'mc_paths': 50_000,              # Reduced for speed\n",
    "        'surface_grid': 80,              # Lower resolution\n",
    "    },\n",
    "}\n",
    "\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "We draw $(S,t,\\sigma)$ uniformly over the ranges specified in the configuration and label each sample with the Black–Scholes closed-form price. Time is bounded away from maturity to avoid numerical instability. The generated arrays are persisted to `data/` for auditability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Data generation (train/val/test)\n",
    "from src.data import generate_dataset\n",
    "contract = CONFIG['contract']\n",
    "splits = generate_dataset(\n",
    "    n_train=CONFIG['data']['n_train'],\n",
    "    n_val=CONFIG['data']['n_val'],\n",
    "    n_test=CONFIG['data']['n_test'],\n",
    "    seed=CONFIG['data']['seed'],\n",
    "    output_dir=DATA_DIR,\n",
    "    K=contract['K'],\n",
    "    T=contract['T'],\n",
    "    r=contract['r'],\n",
    "    t_min=contract['t_min'],\n",
    "    t_max=contract['t_max'],\n",
    "    s_bounds=contract['s_bounds'],\n",
    "    sigma_bounds=contract['sigma_bounds'],\n",
    ")\n",
    "list(splits.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "The training routine applies Adam with warmup, gradient clipping, and adaptive sampling concentrated on high-PDE-residual regions. The gradient penalty weight `lambda_reg` moderates surface smoothness, especially for Δ and Γ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Train PINN\n",
    "from src.train import train\n",
    "checkpoint_path = RUN_RESULTS_DIR / 'pinn_checkpoint.pt'\n",
    "plot_path = FIG_DIR / 'loss_curves.html'\n",
    "log_path = RUN_RESULTS_DIR / 'training_history.json'\n",
    "model, history = train(\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=(device.type == 'cuda'),\n",
    "    epochs=CONFIG['train']['epochs'],\n",
    "    lr=CONFIG['train']['lr'],\n",
    "    batch_size=CONFIG['train']['batch_size'],\n",
    "    data_path=DATA_DIR / 'synthetic_train.npy',\n",
    "    val_path=DATA_DIR / 'synthetic_val.npy',\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    device=device,\n",
    "    adaptive_sampling=CONFIG['train']['adaptive_sampling'],\n",
    "    adaptive_every=CONFIG['train']['adaptive_every'],\n",
    "    adaptive_points=CONFIG['train']['adaptive_points'],\n",
    "    adaptive_radius=CONFIG['train']['adaptive_radius'],\n",
    "    adaptive_eval_samples=CONFIG['train']['adaptive_eval_samples'],\n",
    "    use_warmup=CONFIG['train']['use_warmup'],\n",
    "    warmup_steps=CONFIG['train']['warmup_steps'],\n",
    "    grad_clip=CONFIG['train']['grad_clip'],\n",
    "    save_checkpoint=True,\n",
    "    plot_losses=True,\n",
    "    plot_path=plot_path,\n",
    "    log_path=log_path,\n",
    "    lambda_reg=CONFIG['train']['lambda_reg'],\n",
    "    boundary_weight=CONFIG['train']['boundary_weight'],\n",
    "    boundary_warmup=CONFIG['train']['boundary_warmup'],\n",
    ")\n",
    "history[-1] if history else 'Loaded existing checkpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 4.1 Loss Trajectories\n",
    "The Plotly dashboards below provide both linear-scale and log-scale views of the loss components so we can verify balance between the data-fit term and the physics residual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Review saved loss curves\n",
    "from IPython.display import display, HTML\n",
    "loss_html = FIG_DIR / 'loss_curves.html'\n",
    "loss_log_html = FIG_DIR / 'loss_curves_log.html'\n",
    "labels = [\n",
    "    (loss_html, 'Linear scale'),\n",
    "    (loss_log_html, 'Log scale (L_price, L_PDE, L_reg, L_boundary)'),\n",
    "]\n",
    "for html_path, label in labels:\n",
    "    if html_path.exists():\n",
    "        display(HTML(f\"<h4>{label}</h4>\" + html_path.read_text()))\n",
    "    else:\n",
    "        print(f\"{html_path.name} not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 5. Validation Diagnostics\n",
    "Using the validation split, we compute pricing RMSE and Greek MAE relative to analytic Black–Scholes references. This quantifies in-distribution fidelity before moving to out-of-sample tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Validation metrics on synthetic_val\n",
    "from src.preprocessing import normalize_inputs, load_normalization_config\n",
    "from src.utils.black_scholes import bs_greeks\n",
    "\n",
    "val = np.load(DATA_DIR / 'synthetic_val.npy')\n",
    "subset = val if len(val) <= CONFIG['evaluation']['val_subset'] else val[np.random.choice(\n",
    "    len(val), CONFIG['evaluation']['val_subset'], replace=False)]\n",
    "S_np, t_np, sigma_np, price_np = subset.T\n",
    "config = load_normalization_config(DATA_DIR)\n",
    "\n",
    "S = torch.tensor(S_np, dtype=torch.float32, device=device)\n",
    "t = torch.tensor(t_np, dtype=torch.float32, device=device)\n",
    "sigma = torch.tensor(sigma_np, dtype=torch.float32, device=device)\n",
    "\n",
    "features = normalize_inputs(S, t, sigma, config=config)\n",
    "features = features.detach().clone().requires_grad_(True)\n",
    "\n",
    "model.eval()\n",
    "pred = model(features).squeeze()\n",
    "\n",
    "ones = torch.ones_like(pred)\n",
    "grad_feats = torch.autograd.grad(\n",
    "    pred, features, grad_outputs=ones, create_graph=True, retain_graph=True\n",
    ")[0]\n",
    "\n",
    "grad_x_norm = grad_feats[:, 0]\n",
    "grad_tau_norm = grad_feats[:, 1]\n",
    "grad_sigma_norm = grad_feats[:, 2]\n",
    "\n",
    "# ✅ FIXED: Compute second derivative w.r.t. full features tensor\n",
    "d2_feats = torch.autograd.grad(\n",
    "    grad_x_norm,\n",
    "    features,  # Use features, not features[:, 0]\n",
    "    grad_outputs=torch.ones_like(grad_x_norm),\n",
    "    create_graph=True,\n",
    "    retain_graph=True,\n",
    ")[0]\n",
    "d2V_dx_norm2 = d2_feats[:, 0]  # Extract x-x component\n",
    "\n",
    "# Chain rule scaling factors\n",
    "x_range = max(config.x_max - config.x_min, 1e-6)\n",
    "tau_range = max(config.tau_range, 1e-6)\n",
    "sigma_range = max(config.sigma_range, 1e-6)\n",
    "\n",
    "dx_norm_dx = 2.0 / x_range\n",
    "dtau_norm_dtau = 2.0 / tau_range\n",
    "dsigma_norm_dsigma = 2.0 / sigma_range\n",
    "\n",
    "# Compute Greeks with chain rule\n",
    "dV_dx = grad_x_norm * dx_norm_dx\n",
    "delta = dV_dx / S\n",
    "\n",
    "d2V_dx2 = d2V_dx_norm2 * (dx_norm_dx**2)\n",
    "gamma = d2V_dx2 * (1.0 / (S**2)) + dV_dx * (-1.0 / (S**2))\n",
    "\n",
    "theta = -(grad_tau_norm * dtau_norm_dtau)\n",
    "vega = grad_sigma_norm * dsigma_norm_dsigma\n",
    "\n",
    "# Convert to numpy\n",
    "with torch.no_grad():\n",
    "    pred_np = pred.detach().cpu().numpy()\n",
    "    delta_np = delta.detach().cpu().numpy()\n",
    "    gamma_np = gamma.detach().cpu().numpy()\n",
    "    theta_np = theta.detach().cpu().numpy()\n",
    "    vega_np = vega.detach().cpu().numpy()\n",
    "\n",
    "# Compute analytic Greeks and metrics\n",
    "analytic = bs_greeks(S_np, config.K, config.T, t_np, sigma_np, config.r)\n",
    "tau_np = np.clip(config.T - t_np, 1e-6, None)\n",
    "rho_pred_np = tau_np * (S_np * delta_np - pred_np)\n",
    "\n",
    "metrics = {\n",
    "    'price_rmse': float(np.sqrt(np.mean((pred_np - price_np) ** 2))),\n",
    "    'delta_mae': float(np.mean(np.abs(delta_np - analytic['delta']))),\n",
    "    'gamma_mae': float(np.mean(np.abs(gamma_np - analytic['gamma']))),\n",
    "    'theta_mae': float(np.mean(np.abs(theta_np - analytic['theta']))),\n",
    "    'vega_mae': float(np.mean(np.abs(vega_np - analytic['vega']))),\n",
    "    'rho_mae': float(np.mean(np.abs(rho_pred_np - analytic['rho']))),\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 6. Out-of-Sample Benchmark\n",
    "We invoke the evaluation utility to benchmark the PINN against finite-difference and Monte Carlo baselines on held-out data. The function logs metrics and exports interactive plots (2D overlays, error histograms, and 3D surfaces for price, Δ, Γ, Θ, ν, and ρ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Out-of-sample evaluation & visuals\n",
    "from src.test import evaluate_oos\n",
    "import json\n",
    "\n",
    "oos_metrics = evaluate_oos(\n",
    "    data_path=DATA_DIR / 'synthetic_test.npy',\n",
    "    model_path=checkpoint_path,\n",
    "    device=device,\n",
    "    sample_size=CONFIG['evaluation']['sample_size'],\n",
    "    mc_paths=CONFIG['evaluation']['mc_paths'],\n",
    "    seed=CONFIG['data']['seed'],\n",
    "    fig_dir=FIG_DIR / 'oos',\n",
    "    surface_grid=CONFIG['evaluation']['surface_grid'],\n",
    ")\n",
    "with open(RUN_RESULTS_DIR / 'oos_metrics.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(oos_metrics, fp, indent=2)\n",
    "oos_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Browse generated artifacts\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "display(Markdown('### Training History (JSON excerpt)'))\n",
    "history_path = RUN_RESULTS_DIR / 'training_history.json'\n",
    "if history_path.exists():\n",
    "    with open(history_path) as fp:\n",
    "        hist = json.load(fp)\n",
    "    display(hist[-3:])\n",
    "else:\n",
    "    print('No training history found.')\n",
    "\n",
    "display(Markdown('### Saved Loss Curves'))\n",
    "loss_plot = FIG_DIR / 'loss_curves.html'\n",
    "loss_log_plot = FIG_DIR / 'loss_curves_log.html'\n",
    "links = []\n",
    "labels = [\n",
    "    (loss_plot, 'Linear scale'),\n",
    "    (loss_log_plot, 'Log scale (L_price, L_PDE, L_reg, L_boundary)'),\n",
    "]\n",
    "for html_path, label in labels:\n",
    "    if html_path.exists():\n",
    "        rel_path = html_path.relative_to(PROJECT_ROOT)\n",
    "        links.append(f\"- [{label}]({rel_path.as_posix()})\")\n",
    "    else:\n",
    "        print(f'{html_path.name} not found.')\n",
    "if links:\n",
    "    display(Markdown('\\n'.join(links)))\n",
    "\n",
    "\n",
    "display(Markdown('### Out-of-Sample Figures'))\n",
    "oos_dir = FIG_DIR / 'oos'\n",
    "if oos_dir.exists():\n",
    "    html_links = []\n",
    "    for html in sorted(oos_dir.glob('*.html')):\n",
    "        rel_path = html.relative_to(PROJECT_ROOT)\n",
    "        html_links.append(f\"- [{html.name}]({rel_path.as_posix()})\")\n",
    "    if html_links:\n",
    "        display(Markdown('\\n'.join(html_links)))\n",
    "    else:\n",
    "        print('No OOS HTML files found.')\n",
    "else:\n",
    "    print('No OOS figures found.')\n",
    "\n",
    "display(Markdown('### Latest OOS Metrics'))\n",
    "oos_metrics_path = RUN_RESULTS_DIR / 'oos_metrics.json'\n",
    "if oos_metrics_path.exists():\n",
    "    with open(oos_metrics_path) as fp:\n",
    "        display(json.load(fp))\n",
    "else:\n",
    "    print('OOS metrics JSON not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 7. Findings\n",
    "- Run tag: `proposal_full_run` (proposal-scale dataset: 1M train / 100k val / 100k test).\n",
    "- Training history stored under `results/proposal_full_run`; loss dashboards live in `figures/proposal_full_run`.\n",
    "- Validation metrics computed on a 50,000-sample subset of the validation split.\n",
    "- Out-of-sample diagnostics (metrics JSON and interactive surfaces) are saved in `results/proposal_full_run` and `figures/proposal_full_run/oos`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
