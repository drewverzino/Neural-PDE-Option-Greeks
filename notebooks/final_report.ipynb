{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# Final Experiments Notebook — Greeks Estimation via PINNs\n",
    "\n",
    "This notebook is the single source of truth for the final report figures, tables, and metrics. It covers:\n",
    "- Core experiment: seeded PINN training + in-distribution test metrics.\n",
    "- OOD volatility evaluation.\n",
    "- Baselines: finite differences and Monte Carlo.\n",
    "- Ablations: supervised-only price regressor, adaptive sampling toggle, Sobolev λ sweep.\n",
    "- Figures: training curves, price/Greek surfaces, PDE residual heatmap, Gamma smoothness.\n",
    "- Reproducibility: seeds, configs, saved outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "- Uses local `src/` package; run from repo root.\n",
    "- Toggle the run flags to avoid long jobs unless you want to re-train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Add repo root to path so `import src` works when running from notebooks/\n",
    "REPO_ROOT = Path.cwd().resolve()\n",
    "if (REPO_ROOT / 'src').exists():\n",
    "    import sys\n",
    "    sys.path.append(str(REPO_ROOT))\n",
    "else:\n",
    "    # If running from notebooks/, jump one level up\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "    sys.path.append(str(REPO_ROOT))\n",
    "\n",
    "from src import DATA_DIR, RESULTS_DIR, FIGURES_DIR\n",
    "from src.preprocessing import load_normalization_config, normalize_inputs\n",
    "from src.models import PINNModel, load_pinn_checkpoint\n",
    "from src.train import train\n",
    "from src.test import evaluate_oos\n",
    "from src.losses import compute_pde_residual\n",
    "from src.baselines import finite_diff_greeks, mc_pathwise_greeks\n",
    "from src.utils import bs_price\n",
    "\n",
    "# Device and seeds\n",
    "SEED = 7\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Data and normalization\n",
    "Inspect the synthetic data bounds used for all experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta = load_normalization_config(DATA_DIR)\n",
    "meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick peek at the test split statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_path = DATA_DIR / 'synthetic_test.npy'\n",
    "assert test_path.exists(), \"Missing synthetic_test.npy\"\n",
    "S, t, sigma, price = np.load(test_path).T\n",
    "summary = pd.DataFrame({\n",
    "    'S': S,\n",
    "    't': t,\n",
    "    'sigma': sigma,\n",
    "    'price': price,\n",
    "}).describe(percentiles=[0.05, 0.5, 0.95])\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Training configuration\n",
    "The default block trains the PINN with warmup, Sobolev regularization, and adaptive sampling. Set `RUN_TRAIN=True` to retrain; otherwise we load the existing checkpoint in `results/pinn_checkpoint.pt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUN_TRAIN = False  # flip to True to retrain\n",
    "TRAIN_CONFIG = dict(\n",
    "    epochs=50,\n",
    "    lr=5e-4,\n",
    "    batch_size=4096,\n",
    "    data_path=DATA_DIR / 'synthetic_train.npy',\n",
    "    val_path=DATA_DIR / 'synthetic_val.npy',\n",
    "    checkpoint_path=RESULTS_DIR / 'pinn_checkpoint.pt',\n",
    "    device=device,\n",
    "    adaptive_sampling=True,\n",
    "    adaptive_every=5,\n",
    "    adaptive_points=10_000,\n",
    "    adaptive_radius=0.1,\n",
    "    adaptive_eval_samples=50_000,\n",
    "    use_warmup=True,\n",
    "    warmup_steps=500,\n",
    "    warmup_base_lr=1e-5,\n",
    "    grad_clip=1.0,\n",
    "    lambda_reg=0.01,\n",
    "    boundary_weight=1.0,\n",
    "    boundary_warmup=10,\n",
    "    plot_losses=True,\n",
    "    plot_path=FIGURES_DIR / 'training_curves' / 'loss_curves.html',\n",
    "    log_path=RESULTS_DIR / 'training_history.json',\n",
    ")\n",
    "\n",
    "if RUN_TRAIN:\n",
    "    model, history = train(**TRAIN_CONFIG)\n",
    "    print('Training complete; last epoch:', history[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 3. Load trained model\n",
    "Uses the main checkpoint by default; adjust `MODEL_PATH` if you run new experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_PATH = RESULTS_DIR / 'pinn_checkpoint.pt'\n",
    "assert MODEL_PATH.exists(), f\"Missing checkpoint at {MODEL_PATH}\"\n",
    "model = PINNModel().to(device)\n",
    "load_pinn_checkpoint(model, torch.load(MODEL_PATH, map_location=device), strict=False)\n",
    "model.eval()\n",
    "print('Loaded', MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 4. In-distribution evaluation\n",
    "Evaluate on the held-out test set with analytic targets, finite differences, and Monte Carlo baselines (sampled for speed). Adjust `sample_size` or `mc_paths` as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_id = evaluate_oos(\n",
    "    data_path=DATA_DIR / 'synthetic_test.npy',\n",
    "    model_path=MODEL_PATH,\n",
    "    device=device,\n",
    "    sample_size=5000,   # subset for speed; set None for full test set\n",
    "    mc_paths=5000,      # reduce for quick runs; increase for lower variance\n",
    "    seed=SEED,\n",
    "    fig_dir=None,\n",
    ")\n",
    "\n",
    "pd.DataFrame(metrics_id, index=[0]).T.rename(columns={0: 'value'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 5. Out-of-distribution volatility sweep\n",
    "Generate σ ∈ [0.60, 0.65] samples and reuse the same evaluation harness. The synthetic OOD set is saved for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OOD_PATH = DATA_DIR / 'synthetic_ood_vol.npy'\n",
    "if not OOD_PATH.exists():\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    n_ood = 20000\n",
    "    S_ood = rng.uniform(meta.S_min, meta.S_max, n_ood)\n",
    "    t_ood = rng.uniform(meta.t_min, meta.t_max, n_ood)\n",
    "    sigma_ood = rng.uniform(0.60, 0.65, n_ood)\n",
    "    V_ood = bs_price(S_ood, meta.K, T=meta.T, t=t_ood, sigma=sigma_ood, r=meta.r)\n",
    "    np.save(OOD_PATH, np.stack([S_ood, t_ood, sigma_ood, V_ood], axis=1))\n",
    "    print('Saved OOD set to', OOD_PATH)\n",
    "\n",
    "metrics_ood = evaluate_oos(\n",
    "    data_path=OOD_PATH,\n",
    "    model_path=MODEL_PATH,\n",
    "    device=device,\n",
    "    sample_size=5000,\n",
    "    mc_paths=3000,\n",
    "    seed=SEED,\n",
    "    fig_dir=None,\n",
    ")\n",
    "\n",
    "pd.DataFrame(metrics_ood, index=[0]).T.rename(columns={0: 'value'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 6. Surfaces and PDE residuals\n",
    "Produce price/Greek surfaces on a grid and a PDE residual heatmap for the report. Figures are saved to `figures/final/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FIG_OUT = FIGURES_DIR / 'final'\n",
    "FIG_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "s_lin = torch.linspace(meta.S_min, meta.S_max, 40, device=device)\n",
    "sigma_lin = torch.linspace(meta.sigma_min, meta.sigma_max, 40, device=device)\n",
    "Sg, Sigmag = torch.meshgrid(s_lin, sigma_lin, indexing='ij')\n",
    "t_val = torch.full_like(Sg, 1.0)\n",
    "features = normalize_inputs(Sg.flatten(), t_val.flatten(), Sigmag.flatten(), config=meta)\n",
    "features = features.detach().clone().requires_grad_(True)\n",
    "\n",
    "price_grid = model(features).reshape(Sg.shape)\n",
    "\n",
    "# Greeks via autograd\n",
    "ones = torch.ones_like(price_grid.flatten())\n",
    "grad_feats = torch.autograd.grad(price_grid.flatten(), features, grad_outputs=ones, create_graph=True)[0]\n",
    "\n",
    "x_range = max(meta.x_max - meta.x_min, 1e-6)\n",
    "dx_norm_dx = 2.0 / x_range\n",
    "\n",
    "S_flat = Sg.flatten()\n",
    "dV_dx = grad_feats[:, 0] * dx_norm_dx\n",
    "Delta = (dV_dx / S_flat).reshape(Sg.shape)\n",
    "\n",
    "# Second derivative\n",
    "second = torch.autograd.grad(grad_feats[:, 0], features, grad_outputs=torch.ones_like(grad_feats[:, 0]), create_graph=True)[0][:,0]\n",
    "Gamma = (second * (dx_norm_dx**2) * (1.0 / (S_flat**2)) + dV_dx * (-1.0 / (S_flat**2))).reshape(Sg.shape)\n",
    "\n",
    "# PDE residual\n",
    "pde = compute_pde_residual(\n",
    "    model,\n",
    "    Sg.flatten(),\n",
    "    t_val.flatten(),\n",
    "    Sigmag.flatten(),\n",
    "    r=meta.r,\n",
    "    config=meta,\n",
    ").reshape(Sg.shape).detach().cpu().numpy()\n",
    "\n",
    "# Convert to CPU for plotting\n",
    "plots = {\n",
    "    'price': price_grid.detach().cpu().numpy(),\n",
    "    'delta': Delta.detach().cpu().numpy(),\n",
    "    'gamma': Gamma.detach().cpu().numpy(),\n",
    "    'pde_residual': pde,\n",
    "}\n",
    "\n",
    "for name, arr in plots.items():\n",
    "    fig = px.imshow(\n",
    "        arr.T,\n",
    "        x=s_lin.cpu().numpy(),\n",
    "        y=sigma_lin.cpu().numpy(),\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        color_continuous_scale='Viridis',\n",
    "        labels={'x': 'S', 'y': 'sigma', 'color': name},\n",
    "        title=f'{name} @ t=1.0',\n",
    "    )\n",
    "    fig.write_html(FIG_OUT / f'{name}_heatmap.html')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 7. Gamma smoothness (total variation)\n",
    "Compute the total variation of Gamma over the grid as the smoothness metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def total_variation(arr: np.ndarray) -> float:\n",
    "    return float(np.abs(np.diff(arr, axis=0)).sum() + np.abs(np.diff(arr, axis=1)).sum())\n",
    "\n",
    "gamma_tv = total_variation(plots['gamma'])\n",
    "print('Gamma total variation:', gamma_tv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 8. Runtime profiling\n",
    "Measure inference latency (per-sample and batch) on the current device.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_feats = normalize_inputs(\n",
    "        torch.tensor([100.0], device=device),\n",
    "        torch.tensor([1.0], device=device),\n",
    "        torch.tensor([0.2], device=device),\n",
    "        config=meta,\n",
    "    )\n",
    "    batch_feats = normalize_inputs(\n",
    "        torch.tensor(np.linspace(meta.S_min, meta.S_max, 1024, dtype=np.float32), device=device),\n",
    "        torch.tensor(np.linspace(meta.t_min, meta.t_max, 1024, dtype=np.float32), device=device),\n",
    "        torch.tensor(np.linspace(meta.sigma_min, meta.sigma_max, 1024, dtype=np.float32), device=device),\n",
    "        config=meta,\n",
    "    )\n",
    "\n",
    "    # Warmup\n",
    "    _ = model(sample_feats)\n",
    "\n",
    "    def time_fn(fn, iters=50):\n",
    "        torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "        start = time.time()\n",
    "        for _ in range(iters):\n",
    "            fn()\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        return (time.time() - start) / iters\n",
    "\n",
    "    per_sample_ms = time_fn(lambda: model(sample_feats)) * 1000\n",
    "    batch_ms = time_fn(lambda: model(batch_feats)) * 1000\n",
    "\n",
    "print(f'Latency: {per_sample_ms:.4f} ms/sample, {batch_ms:.4f} ms for batch=1024')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 9. Ablations (ready-to-run toggles)\n",
    "- **Supervised-only** (no PDE/BC): trains a plain regressor on price labels.\n",
    "- **No adaptive sampling**: reuse the main PINN config with `adaptive_sampling=False`.\n",
    "- **Sobolev λ sweep**: loop over {0.001, 0.01, 0.1}.\n",
    "\n",
    "These are disabled by default to keep the notebook fast; flip the flags to generate additional curves/metrics for the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUN_SUPERVISED_ONLY = True\n",
    "RUN_NO_ADAPTIVE = True\n",
    "RUN_LAMBDA_SWEEP = True\n",
    "\n",
    "if RUN_SUPERVISED_ONLY:\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    data = np.load(DATA_DIR / 'synthetic_train.npy')\n",
    "    tensors = [torch.tensor(data[:, i], dtype=torch.float32) for i in range(4)]\n",
    "    loader = DataLoader(TensorDataset(*tensors), batch_size=4096, shuffle=True)\n",
    "    sup_model = PINNModel().to(device)\n",
    "    opt = torch.optim.Adam(sup_model.parameters(), lr=1e-3)\n",
    "    sup_history = []\n",
    "    for epoch in range(10):\n",
    "        sup_model.train()\n",
    "        losses = []\n",
    "        for S, t, sigma, V in loader:\n",
    "            S = S.to(device); t = t.to(device); sigma = sigma.to(device); V = V.to(device)\n",
    "            feats = normalize_inputs(S, t, sigma, config=meta)\n",
    "            pred = sup_model(feats).squeeze(-1)\n",
    "            loss = torch.mean((pred - V) ** 2)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        sup_history.append(float(np.mean(losses)))\n",
    "        print(f'[Supervised] epoch {epoch+1}: loss={sup_history[-1]:.4f}')\n",
    "\n",
    "if RUN_NO_ADAPTIVE:\n",
    "    cfg = TRAIN_CONFIG.copy()\n",
    "    cfg.update(dict(adaptive_sampling=False, checkpoint_path=RESULTS_DIR / 'pinn_no_adaptive.pt', log_path=RESULTS_DIR / 'history_no_adaptive.json'))\n",
    "    _, _ = train(**cfg)\n",
    "\n",
    "if RUN_LAMBDA_SWEEP:\n",
    "    sweep_results = []\n",
    "    for lam in [0.001, 0.01, 0.1]:\n",
    "        cfg = TRAIN_CONFIG.copy()\n",
    "        cfg.update(dict(lambda_reg=lam, checkpoint_path=RESULTS_DIR / f'pinn_lambda_{lam}.pt', log_path=RESULTS_DIR / f'history_lambda_{lam}.json'))\n",
    "        _, hist = train(**cfg)\n",
    "        sweep_results.append({'lambda': lam, 'final_loss': hist[-1]['loss']})\n",
    "    display(pd.DataFrame(sweep_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 10. Export summary table for the report\n",
    "Collect the key metrics (ID vs OOD) and write them to `results/final_summary.csv` for easy inclusion in the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {'split': 'in_distribution', **metrics_id},\n",
    "    {'split': 'ood_vol', **metrics_ood},\n",
    "])\n",
    "summary_path = RESULTS_DIR / 'final_summary.csv'\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "summary_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
