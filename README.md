# CS 4644/7643: Greeks Estimation via Physics-Informed Neural Networks

## ðŸ“˜ Overview

This repository contains the implementation for our **Deep Learning course project** at Georgia Tech â€” *Greeks Estimation via Physics-Informed Neural Networks (PINNs)*. The project explores how **deep neural networks** can be trained to **satisfy the Blackâ€“Scholes partial differential equation (PDE)** directly through the loss function, enabling accurate, efficient, and smooth computation of **option Greeks** (Î”, Î“, Î˜, Î½, Ï).

Traditional methods such as finite-difference and Monte Carlo simulations either produce noisy estimates or are computationally expensive, especially for higher-order Greeks. PINNs provide a powerful alternative by enforcing known physical (in this case, financial) laws during training.

---

## ðŸŽ¯ Project Objectives

1. **Model Goal:** Develop a PINN that predicts option prices and Greeks simultaneously without retraining across volatility regimes.
2. **Key Innovation:** Include volatility (Ïƒ) as an explicit network input to generalize across different volatility surfaces.
3. **Evaluation:** Compare against classical baselines (Finite Difference, Monte Carlo, fixed-Ïƒ PINN) using metrics such as RMSE, total variation smoothness, and training stability.
4. **Application:** Improve the interpretability, efficiency, and numerical stability of deep learning models in quantitative finance.

---

## ðŸ“… Deliverable Timeline

| Deliverable | Due Date | Description | Weight |
|:--|:--|:--|:--:|
| **Project Proposal** | Oct 1, 2025 | Define problem, related work, and plan | 1% |
| **Milestone Report** | Nov 3, 2025 | 4-page CVPR-style progress report | 10% |
| **Final Report** | Nov 30, 2025 | 6â€“8 page CVPR-style full paper | 20% |
| **Poster Session** | Dec 1, 2025 | In-person presentation (Klaus Atrium) | 5% |

---

## ðŸ§± Repository Structure

```
cs4644-pinn-greeks/
â”‚
â”œâ”€â”€ README.md                 # Project overview and setup guide
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .gitignore                # Ignored files (datasets, logs, checkpoints)
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ data.py               # Data generation & preprocessing
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ black_scholes.py  # Analytic pricing and Greek functions
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ pinn_model.py     # PINN architecture (Residual Network)
â”‚   â”œâ”€â”€ losses.py             # Custom loss functions (L_price, L_PDE, etc.)
â”‚   â”œâ”€â”€ train.py              # Training loop & adaptive sampling
â”‚   â””â”€â”€ eval.py               # Evaluation metrics and diagnostics
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ 01_data_visualization.ipynb
â”‚   â”œâ”€â”€ 02_baseline_experiments.ipynb
â”‚   â””â”€â”€ 03_training_diagnostics.ipynb
â”‚
â”œâ”€â”€ data/                     # Synthetic training and validation sets
â”‚   â”œâ”€â”€ synthetic_train.npy
â”‚   â””â”€â”€ synthetic_val.npy
â”‚
â”œâ”€â”€ results/                  # Stored outputs, metrics, and tables
â”‚   â”œâ”€â”€ baseline_fd.csv
â”‚   â”œâ”€â”€ baseline_mc.csv
â”‚   â”œâ”€â”€ pinn_results.csv
â”‚   â”œâ”€â”€ ablation_study.csv
â”‚   â””â”€â”€ logs/                 # Training logs and W&B runs
â”‚
â”œâ”€â”€ figures/                  # Visualizations and plots
â”‚   â”œâ”€â”€ data_exploration/
â”‚   â”œâ”€â”€ training_curves/
â”‚   â”œâ”€â”€ residual_heatmaps/
â”‚   â””â”€â”€ final_results/
â”‚
â””â”€â”€ reports/                  # Written deliverables
    â”œâ”€â”€ milestone/
    â”‚   â””â”€â”€ milestone_report.pdf
    â”œâ”€â”€ final/
    â”‚   â””â”€â”€ final_report.pdf
    â””â”€â”€ poster/
        â””â”€â”€ poster.pdf
```

---

## âš™ï¸ Environment Setup

Create and activate a virtual environment:

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### `requirements.txt`
```
torch>=2.1
torchvision
numpy
scipy
pandas
matplotlib
seaborn
tqdm
wandb
jupyter
```
Optional (for LaTeX report compilation):
```
pylatexenc
```
---

## ðŸ’¡ Implementation Details

### **1. Data Generation**
- Synthetic dataset generated from **Blackâ€“Scholes closed-form solution**.
- Inputs: stock price (S), time to maturity (t), volatility (Ïƒ).  
- Preprocessing: log-moneyness (x = ln(S/K)) and scaled time (Ï„ = Tâ€“t).  
- Training/validation split: 1,000,000 train / 100,000 validation points.

### **2. Model Architecture**
- Fully connected **Residual Network** (5 layers Ã— 128 neurons, ReLU).  
- Input: (S, t, Ïƒ) â†’ Output: option price `VÎ¸(S, t, Ïƒ)`.  
- Residual connections stabilize gradient flow across layers.

### **3. Physics-Informed Loss**
\`\`\`math
L = L_{price} + Î± L_{PDE} + Î² L_{boundary} + Î»â€–âˆ‚_{SS}VÎ¸â€–Â²
\`\`\`
- `L_price`: MSE between predicted and analytic prices.  
- `L_PDE`: PDE residual enforcing the Blackâ€“Scholes equation.  
- `L_boundary`: Terminal payoff condition \( V(T, S) = max(S-K, 0) \).  
- `Î»â€–âˆ‚SSVâ€–Â²`: Sobolev penalty for smoother Î“ estimates.  

### **4. Baselines**
1. **Blackâ€“Scholes analytic** (ground truth)  
2. **Finite Difference** (Îµ-shift Î”, Î“)  
3. **Monte Carlo** (pathwise estimator)  
4. **Fixed-Ïƒ PINN** (retrained per volatility)

### **5. Evaluation Metrics**
| Metric | Description |
|:--|:--|
| **RMSE (V, Î”, Î“, Î˜, Î½)** | Error vs analytic Greeks |
| **Total Variation (Î“)** | Smoothness measure |
| **Runtime (ms)** | Inference efficiency |
| **Training Stability** | Convergence under adaptive sampling |

---

## ðŸš€ How to Run

### **Generate Data**
```bash
python src/data.py --n_train 1000000 --n_val 100000 --seed 42
```

### **Train PINN**
```bash
python src/train.py --epochs 100 --lr 1e-3 --batch_size 4096 --lambda_sobolev 0.01
```

### **Evaluate Baselines**
```bash
python src/eval.py --compare baselines
```

### **Plot Results**
```bash
python notebooks/03_training_diagnostics.ipynb
```

---

## ðŸ“Š Outputs & Visualizations

Expected visual outputs include:

- **Loss Curves:** L_price, L_PDE, L_boundary, total loss vs epoch  
- **PDE Residual Heatmaps:** visualize model satisfaction of PDE constraints  
- **Surface Plots:** Î”(S, Ïƒ), Î“(S, Ïƒ), Î½(S, Ïƒ) across multiple expiries  
- **RMSE Tables:** model vs baselines (Blackâ€“Scholes, FD, MC)  
- **Ablation Charts:** performance vs network depth & Sobolev Î»

---

## ðŸ§© Future Extensions

1. **Volatility Surface Calibration:** Extend from constant Ïƒ to implied volatility surfaces (SVI).  
2. **PINN for Exotic Options:** Apply to barrier or Asian options with path dependency.  
3. **Physics-Augmented Transformers:** Replace MLP with attention layers for higher flexibility.  
4. **Greeks Sensitivity Analysis:** Use automatic differentiation to visualize interdependence of Greeks.

---

## ðŸ‘¥ Team Members

| Name | Role | Responsibilities | Contact |
|:--|:--|:--|:--|
| **Drew Verzino** | Model / Training Lead | Model architecture, training scripts, report writing | |
| **Rahul Rajesh** | Math / PDE Lead | PINN loss design, PDE validation, theoretical background | |
| **Aditya Deb** | Data & Preprocessing Lead | Synthetic data generation, scaling, baseline integration | |
| **Navin Senthil** | Visualization / Reporting Lead | Diagnostic plots, LaTeX reports, poster design | |

---

## ðŸ“š References

1. Raissi, M., Perdikaris, P., & Karniadakis, G. E. (2019). *Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear PDEs.* Journal of Computational Physics, 378, 686â€“707.  
2. Tanios, R. (2021). *Physics Informed Neural Networks in Computational Finance: High Dimensional Forward & Inverse Option Pricing.* ETH ZÃ¼rich Thesis.  
3. Bae, H.-O., Kang, S., & Lee, M. (2024). *Option Pricing and Local Volatility Surface by Physics-Informed Neural Network.* Computational Economics, 64(5), 3143â€“3159.  
4. du Plooy, R., & Venter, P. (2024). *Approximating Option Greeks in a Classical and Multi-Curve Framework Using Artificial Neural Networks.* Journal of Risk and Financial Management, 17(4):140.  
5. Gao, Q., Wang, Z., Zhang, R., & Wang, D. (2025). *Adaptive Movement Sampling Physics-Informed Residual Network (AM-PIRN) for Solving Nonlinear Option Pricing Models.* arXiv preprint arXiv:2504.03244.

---

## ðŸ§¾ License

This repository is for **academic use only** under the Georgia Tech CS 4644/7643 Deep Learning course. Redistribution or commercial use is prohibited without explicit permission from the course instructors.

---

**Â© 2025 â€” Georgia Institute of Technology | CS 4644/7643 Deep Learning Project**
